\section{Literature Review}
\subsection{Problems of Software Engineering}
Software has become an integral part of our daily lives. Certain expectations are made regarding the quality of software in terms of reliability, security and efficiency. These expectations come with challenges for the software developers across all industries.
To efficiently deal with these challenges, software engineers have tried for decades to develop methods and guides to overcome these issues. However in 1986 Frederick Brooks published his paper `No Silver Bullet' \footcite{brooksNoSilverBullet1987} 
in which he argues that: `\ldots building software will always be hard. There is inherently no silver bullet.' \footcite[3]{brooksNoSilverBullet1987}. He based this statement of the fact that there two types of difficulty in software development: the essential and the accidental.
The essential difficulties he names are complexity, conformity, changeability and invisibility. With complexity Brooks wants to describe the inherit intricacy of software systems: `Software entities are more complex for their size than perhaps any other human construct, because no two parts are alike'.\footcite[3]{brooksNoSilverBullet1987}
According to him this complexity makes `conceiving, describing, and testing them hard'\footcite[3]{brooksNoSilverBullet1987}.
The second essential Brooks names is conformity. To explain this he compares software development to physics. Even though they are similar complex, physics has the advantage on relying on a single set of laws or `creator'. The same cannot be said for software engineers. Brooks claims that
the complexity is of `arbitrary complexity, forced without rhyme or reason by the many human institutions and systems to which his interfaces must conform'\footcite[4]{brooksNoSilverBullet1987}. This is due to software being perceived as `the most comfortable'\footcite[4]{brooksNoSilverBullet1987} thing to change in a system.
Brooks explains the changeability issue by comparing software to other products like cars or computers. With these types of products, changes are difficult to make once the product is released. Software however is just `pure thought-stuff, infinitely malleable.'\footcite[4]{brooksNoSilverBullet1987} Another big part of the changeability issue
the fact that software often `survives beyond the normal life of the machine vehicle for which it is first written'\footcite[4]{brooksNoSilverBullet1987}. This means that software has to be adapted to new machines causing an extended life time of the software.
Invisibility is the last essential difficulty Brooks names. With this he means the difficulty to visualize software compared to other products. This makes the not only the creation difficult but also `severely hinders communication among minds'\footcite[4]{brooksNoSilverBullet1987}.
According to Brooks these issues are in `the very nature of software' \footcite[2]{brooksNoSilverBullet1987}. For him these difficulty are unlikely to be solved unlike the accidental difficulties.\\

In contrast the accidental difficulties arise from limitations of current languages, tools and methodologies. Brooks notes that these issuesâ€”such as inefficient programming environments, suboptimal development processes and integration challenges can be overcome as the industry improves its practices and technologies.
For example the adaptation of agile methodologies, integrated development environments and continuous integration have helped to overcome some of these accidental difficulties.\\

The persistent nature of these challenges Brooks presented have been since been substantiated by later empirical research. For instance, Lehman and Ramil (2003)\footcite{lehmanSoftwareEvolutionBackground2003} discussed in their paper that software systems that are left unchecked will experience a decline in quality over time.
This phenomenon is encapsulated in Lehman's laws of software evolution, which he formulated in multiple papers. In their paper `Software evolution - Background, theory, practice' Lehman and Ramil present empirical observations that support the notion that software quality tends to deteriorate over time - a phenomenon often described als
software decay. 

\subsection{Software Decay and Technical Debt}
The term software decay was empirically studied and statistically validated by Eick et al.\ in their influential paper `Does Code Decay? Assessing the Evidence from Change Management Data'(2001)\footcite{eickDoesCodeDecay2001}. They begin by stating that `software does not age or "wear out" in the conventional sense.' \footcite[1]{eickDoesCodeDecay2001}
If nothing in the environment changes, the software could run forever. However, this is almost never the case as mainly two things change constantly: the hard- and software environments and the requirements of the software.\\

This is in accordance with the first two laws of Program Evolution Dynamics formulated by Belady and Lehman(1976).
The first law states: `A system that is used undergoes continuing change until it is judged more cost effective to freeze and recreate it.'\footcite[228]{beladyModelLargeProgram1976}
Building on this, their second law suggests: `The entropy of a system (its unstructuredness) increases with time, unless specific work is executed to maintain or reduce it.'\footcite[228]{beladyModelLargeProgram1976}\\

Eick et al.\ analysis provides empirical validation for these theoretical laws, offering `very strong evidence that code does decay.'\footcite[7]{eickDoesCodeDecay2001}
They base this conclusion on their findings that `the span of changes increases over time'\footcite[7]{eickDoesCodeDecay2001} meaning that modifications to the software tend to affect increasingly larger parts of the system as the software evolves. This growth in the span of changes indicates - and potentially leads to -
a breakdown in the software's modularity. Consequently the software becomes `more difficult to change than it should be,'\footcite[3]{eickDoesCodeDecay2001} measured specifically by three criteria: cost of change, time to implement change and the resulting quality of the software.
Therefore, the combination of theoretical insights from Lehman and Belday and empirical data from Eick et al. paints a clear picture: software decay is an inevitable consequence of ongoing evolution unless consciously and proactively managed through structured efforts such as continuous refactoring and architectural vigilance.\\

The concept of software decay aligns closely with earlier theoretical discussions by David Parnas (1994). In his influential paper `Software Aging' Parnas describes software aging as a progressive deterioration of a program's internal quality primarily due to frequent, 
inadequately documented modifications which he termed `Ignorant surgery'\footcite[280]{296790}, as well as the failure to continuously adapt the architecture to evolving needs which he called `Lack of movement'\footcite[280]{296790}.
Without this proactive maintenance and refactoring effort, Parnas argues that software inevitably reaches a state where changes become more riskier, more costly and error-prone\footcite[280-281]{296790}.

//TODO: Emperical studies like Banker or Bieman maybe?

The term `Technical Debt' was first coined by Ward Cunningham in his paper `The WyCash Portfolio Management System'(1992)\footcite{cunninghamWyCashPortfolioManagement1992} This metaphor was used to describe the trade-off between a quickly implemented solution and a thought out process. 
When ones uses the quick solution it `is like going into debt.'\footcite[2]{cunninghamWyCashPortfolioManagement1992} Cunningham argues that this debt accumulates interest if not repaid or rewritten. 
If this does not happen Cunningham warns that `Entire engineering organizations can be brought to a stand-still under the debt load of an unconsolidated implementation'\footcite[2]{cunninghamWyCashPortfolioManagement1992}.\\

This term was further built upon and refined by the industry through white papers like `Technical Debt' by Steve McConnell(2008)\footcite{mcconnellManagingTechnicalDebt2017} or the `Technical Debt Quadrant' by Martin Fowler (2009)\footcite{fowlerTechnicalDebtQuadrant2009}.
McConnell differentiates between two types of technical debt: Unintentional and Intentional \footcite[3]{mcconnellManagingTechnicalDebt2017}. The first results from bad code, inexperience or unknowingly taking over a project with technical debt.
The second type is taken on purpose `to optimize for the present rather than for the future.'\footcite[3]{mcconnellManagingTechnicalDebt2017} As the first is not planned, it is difficult to avoid it. The second type however can be managed and controlled.\\
Additionally, McConnell differentiates between different types of intentional debt. According to him, debt can be taken on short-term or long-term. The short-term debt is taken on to meet a deadline or to deliver a feature. Therefore it is `taken on tactically or reactively'\footcite[3]{mcconnellManagingTechnicalDebt2017}.
The long-term debt on the other hand is more strategic and is taken on to help the team in a bigger picture. The difference between those two is that short-term debt `should be paid of quickly, perhaps as the first part of the next release cycle'\footcite[4]{mcconnellManagingTechnicalDebt2017}, while 
long-term debt is something companies can be carried for years.\\
Martin Fowler on the other hand warned in taking on too much deliberate debt. He argues that `Even the best teams will have debt to deal with as a project goes on - even more reason not to overload it with crummy code.'\footcite{fowlerTechnicalDebtQuadrant2009}
He created a quadrant between reckless and prudent and deliberate and inadvertent. The difference between reckless and prudent for Fowler is the way the debt is taken on. Reckless debt happens without the right evaluation of the consequences, risking difficulties in the future. Prudent on the other hand is taken on
with the trade-offs in mind and the knowledge of the future costs. Fowler differentiates between deliberate and inadvertent is similar to McConnell's differentiation between intentional and unintentional debt.
The combination of those four result in either quick solutions without considering the long-term impact (reckless and deliberate), flawed design or implementation, either carelessly or unknowingly (reckless and inadvertent), 
purposefully taking on debt to gain a short-term advantage with plans of repayment (prudent and deliberate) or taking on debt due to lack of knowledge or experience (prudent and inadvertent).\\

In their article `Technical Debt: From Metaphor to Theory and Practice' (2012) Kruchten et al.\ \footcite{kruchtenTechnicalDebtMetaphor2012} criticize the concept of technical to be `somewhat diluted lately' \footcite[18]{kruchtenTechnicalDebtMetaphor2012}, stating that every issue in software development was called some form of debt. 
Therefore they set out do define `a theoretical foundation'\footcite[19]{kruchtenTechnicalDebtMetaphor2012} for technical debt.\\
Kruchten et al.\ state that technical debt has become more than the initial coding shortcuts and rather encompasses all kinds of internal software quality comprises.\footcite[19]{kruchtenTechnicalDebtMetaphor2012}
According to them this includes architectural debt, `documentation and testing'\footcite[20]{kruchtenTechnicalDebtMetaphor2012} as well as requirements and infrastructure debt.
All these debt types allow engineers to better discuss the trade-offs with stakeholders and to make better decisions.\\
Additionally, Kruchten et al. build upon the metaphor of Cunnigham 
